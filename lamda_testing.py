import json
import boto3
import pandas as pd
import numpy as np

# Define a sample JSON input
sample_json_input = {
    "corexemain": False,
    "msvbvm60.dll": False,
    "e_lfanew": 256,
    "NumberOfSections": 10,
    "TimeDateStamp": 1676472856,
    "Characteristics": 33167,
    "MajorLinkerVersion": 2,
    "SizeOfCode": 741888,
    "SizeOfInitializedData": 213504,
    "AddressOfEntryPoint": 745196,
    "BaseOfCode": 4096,
    "MajorImageVersion": 6,
    "SizeOfImage": 1011712,
    "CheckSum": 15840358,
    "DllCharacteristics": 33088,
    "text_Misc_VirtualSize": "N/A",
    "text_VirtualAddress": "N/A",
    "text_SizeOfRawData": "N/A",
    "data_Misc_VirtualSize": "N/A",
    "data_VirtualAddress": "N/A",
    "data_SizeOfRawData": "N/A",
    "data_PointerToRawData": "N/A",
    "rsrc_Misc_VirtualSize": "N/A",
    "rsrc_VirtualAddress": "N/A",
    "rsrc_SizeOfRawData": "N/A",
    "rsrc_PointerToRawData": "N/A",
    "reloc_VirtualAddress": "N/A",
    "reloc_PointerToRawData": "N/A"
}

def preprocess_data(features):
    df = pd.DataFrame(features, index=[0])
    df = df.replace('N/A', 0)
    df = df.astype(int)
    skew_list = ['NumberOfSections', 'TimeDateStamp', 'Characteristics', 'MajorLinkerVersion', 'MinorLinkerVersion', 'SizeOfCode', 'SizeOfInitializedData', 'SizeOfUninitializedData', 'AddressOfEntryPoint', 'BaseOfCode', 'FileAlignment', 'MajorOperatingSystemVersion', 'MajorImageVersion', 'SizeOfImage', 'SizeOfHeaders', 'CheckSum', 'text_Misc_VirtualSize', 'text_VirtualAddress', 'text_SizeOfRawData', 'text_PointerToRawData', 'data_Misc_VirtualSize', 'data_VirtualAddress', 'data_SizeOfRawData', 'data_PointerToRawData', 'rdata_Misc_VirtualSize', 'rdata_VirtualAddress', 'rdata_SizeOfRawData', 'rdata_PointerToRawData', 'rsrc_Misc_VirtualSize', 'rsrc_VirtualAddress', 'rsrc_SizeOfRawData', 'rsrc_PointerToRawData', 'rsrc_Characteristics', 'reloc_Misc_VirtualSize', 'reloc_VirtualAddress', 'reloc_SizeOfRawData', 'reloc_PointerToRawData']
    
    # Apply log1p transformation to columns in skew_list if they exist in the DataFrame
    for column in skew_list:
        if column in df:
            df[column] = np.log1p(df[column])
        else:
            print(f"Column '{column}' not found in input features.")
    
    return df



def save_to_s3(df):
    # Save DataFrame to S3 bucket (collected_data.csv)
    # For local testing, just print the DataFrame
    print(df)

def invoke_sagemaker_endpoint(df, aws_access_key_id, aws_secret_access_key, aws_region):
    try:
        # Convert DataFrame to JSON string
        input_payload = df.to_json(orient='records')

        # Define the endpoint name
        endpoint_name = 'guardiana-endpoint' 

        # Create a session using AWS credentials and specify the region
        session = boto3.Session(
            aws_access_key_id=aws_access_key_id,
            aws_secret_access_key=aws_secret_access_key,
            region_name=aws_region
        )

        # Create a SageMaker runtime client
        sagemaker_runtime = session.client('sagemaker-runtime')

        # Define the content type of the input payload
        content_type = 'application/json'

        # Perform a real-time inference by sending a request to the SageMaker endpoint
        response = sagemaker_runtime.invoke_endpoint(
            EndpointName=endpoint_name,
            ContentType=content_type,
            Body=input_payload
        )

        # Read the response from the endpoint
        response_body = response['Body'].read()

        # Parse the JSON response
        predictions = json.loads(response_body)

        return predictions
    except Exception as e:
        print(f"Error invoking SageMaker endpoint: {e}")
        return None
# Specify your AWS credentials and region
aws_access_key_id = 'AKIAZQ3DU546TZZVW3UP'
aws_secret_access_key = 'RhcIonQmsK13RvFz6X4pBSSW4+k3cYkwwyq3+i7p'
aws_region = 'us-east-1'



    
# Preprocess the sample JSON input
preprocessed_data = preprocess_data(sample_json_input)

# Save preprocessed data to S3 (for local testing, print the DataFrame)
save_to_s3(preprocessed_data)

# Trigger SageMaker inference (for local testing, print a placeholder prediction)
prediction = invoke_sagemaker_endpoint(preprocessed_data, aws_access_key_id, aws_secret_access_key, aws_region)
# Print the prediction
print("Prediction:", prediction)
